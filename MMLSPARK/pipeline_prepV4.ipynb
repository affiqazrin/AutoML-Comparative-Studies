{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import time\n",
    "import pyspark\n",
    "import findspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.feature import *\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler, IndexToString\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, when, explode\n",
    "from pyspark.sql import SparkSession, SQLContext, Row, HiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "\n",
    "# Creatingt Spark SQL environment\n",
    "spark =SparkSession\\\n",
    "   .builder\\\n",
    "   .appName(\"test\")\\\n",
    "   .enableHiveSupport().getOrCreate()\n",
    "\n",
    "sc= spark.sparkContext\n",
    "sqlContext= SQLContext(sc)\n",
    "\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark is an existing SparkSession\n",
    "train = sqlContext.read.format(\"csv\")\\\n",
    "   .option(\"header\", \"true\")\\\n",
    "   .load(\"C:/Users/affiqazrin/Desktop/dataset/Data_FinalProject.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target (y=deposit)\n",
    "train.groupBy(\"y\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Feature Types\n",
    "train.createOrReplaceTempView(\"train\")\n",
    "\n",
    "train = spark.sql(\"select \\\n",
    "                    cast(age as int) as age, \\\n",
    "                    cast(job as string) as job, \\\n",
    "                    cast(marital as string) as marital, \\\n",
    "                    cast(education as string) as education, \\\n",
    "                    cast(default as string) as default, \\\n",
    "                    cast(housing as string) as housing, \\\n",
    "                    cast(loan as string) as loan, \\\n",
    "                    cast(contact as string) as contact, \\\n",
    "                    cast(day_of_week as string) as day, \\\n",
    "                    cast(month as string) as month, \\\n",
    "                    cast(duration as int) as duration, \\\n",
    "                    cast(campaign as int) as campaign, \\\n",
    "                    cast(pdays as int) as pdays, \\\n",
    "                    cast(previous as int) as previous, \\\n",
    "                    cast(poutcome as string) as poutcome, \\\n",
    "                    cast(y as string) as deposit \\\n",
    "                from train\")\n",
    "\n",
    "# Data Types\n",
    "train.dtypes\n",
    "[('age', 'int'),\n",
    " ('job', 'string'),\n",
    " ('marital', 'string'),\n",
    " ('education', 'string'),\n",
    " ('default', 'string'),\n",
    " ('housing', 'string'),\n",
    " ('loan', 'string'),\n",
    " ('contact', 'string'),\n",
    " ('day', 'string'),\n",
    " ('month', 'string'),\n",
    " ('duration', 'int'),\n",
    " ('campaign', 'int'),\n",
    " ('pdays', 'int'),\n",
    " ('previous', 'int'),\n",
    " ('poutcome', 'string'),\n",
    " ('deposit', 'string')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping null values\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting in train and test set. Beware : It sorts the dataset\n",
    "(traindf, testdf) = train.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "jobIndexer = StringIndexer(inputCol='job', outputCol=\"indexedJob\")\n",
    "maritalIndexer = StringIndexer(inputCol='marital', outputCol=\"indexedMarital\")\n",
    "educationIndexer = StringIndexer(inputCol='education', outputCol=\"indexedEducation\")\n",
    "\n",
    "housingIndexer = StringIndexer(inputCol='housing', outputCol=\"indexedHousing\")\n",
    "loanIndexer = StringIndexer(inputCol='loan', outputCol=\"indexedLoan\")\n",
    "contactIndexer = StringIndexer(inputCol='contact', outputCol=\"indexedContact\")\n",
    "\n",
    "dayIndexer = StringIndexer(inputCol='day', outputCol=\"indexedDay\")\n",
    "monthIndexer = StringIndexer(inputCol='month', outputCol=\"indexedMonth\")\n",
    "poutcomeIndexer = StringIndexer(inputCol='poutcome', outputCol=\"indexedPoutcome\")\n",
    "\n",
    "depositIndexer = StringIndexer(inputCol='deposit', outputCol=\"indexedDeposit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoder on indexed features\n",
    "jobEncoder = OneHotEncoder(inputCol='indexedJob', outputCol=\"jobVec\").setDropLast(False)\n",
    "maritalEncoder = OneHotEncoder(inputCol='indexedMarital', outputCol=\"maritalVec\").setDropLast(False)\n",
    "educationEncoder = OneHotEncoder(inputCol='indexedEducation', outputCol=\"educationVec\").setDropLast(False)\n",
    "\n",
    "housingEncoder = OneHotEncoder(inputCol='indexedHousing', outputCol=\"housingVec\").setDropLast(False)\n",
    "loanEncoder = OneHotEncoder(inputCol='indexedLoan', outputCol=\"loanVec\").setDropLast(False)\n",
    "contactEncoder = OneHotEncoder(inputCol='indexedContact', outputCol=\"contactVec\").setDropLast(False)\n",
    "\n",
    "dayEncoder = OneHotEncoder(inputCol='indexedDay', outputCol=\"dayVec\").setDropLast(False)\n",
    "monthEncoder = OneHotEncoder(inputCol='indexedMonth', outputCol=\"monthVec\").setDropLast(False)\n",
    "poutcomeEncoder = OneHotEncoder(inputCol='indexedPoutcome', outputCol=\"poutcomeVec\").setDropLast(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['age',\n",
    "                                       'duration',\n",
    "                                       'campaign',\n",
    "                                       'pdays',\n",
    "                                       'previous',\n",
    "                                       \"jobVec\",\n",
    "                                       \"maritalVec\",\n",
    "                                       \"educationVec\",\n",
    "                                       \"housingVec\",\n",
    "                                       \"loanVec\",\n",
    "                                       \"contactVec\",\n",
    "                                       \"dayVec\",\n",
    "                                       \"monthVec\",\n",
    "                                       \"poutcomeVec\",],outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedDeposit\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a GradientBoostedTreeClassifier model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedDeposit\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedDeposit\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[jobIndexer,\n",
    "                            maritalIndexer,\n",
    "                            educationIndexer,\n",
    "                            housingIndexer,\n",
    "                            loanIndexer,\n",
    "                            contactIndexer,\n",
    "                            dayIndexer,\n",
    "                            monthIndexer,\n",
    "                            poutcomeIndexer,\n",
    "                            \n",
    "                            jobEncoder,\n",
    "                            maritalEncoder,\n",
    "                            educationEncoder,\n",
    "                            housingEncoder,\n",
    "                            loanEncoder,\n",
    "                            contactEncoder,\n",
    "                            dayEncoder,\n",
    "                            monthEncoder,\n",
    "                            poutcomeEncoder,\n",
    "                            \n",
    "                            assembler,\n",
    "                            \n",
    "                            depositIndexer,\n",
    "                            rf])\n",
    " \n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(traindf)\n",
    " \n",
    "# Predictions\n",
    "predictions = model.transform(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select example rows to display.\n",
    "predictions.columns \n",
    " \n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\",\n",
    "                   \"deposit\",\n",
    "                   \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.toPandas().to_csv('Data_FinalProject_READY2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "predictions = predictions.select(col(\"deposit\").cast(\"Float\"),col(\"prediction\"))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"deposit\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = model.stages[6]\n",
    "print(rfModel)  # summary only\n",
    " \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"deposit\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    " \n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"deposit\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n",
    " \n",
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"deposit\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)\n",
    " \n",
    "evaluatorwr = MulticlassClassificationEvaluator(labelCol=\"deposit\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "wr = evaluatorwr.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
