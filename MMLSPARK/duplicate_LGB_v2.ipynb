{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from math import sqrt\n",
    "import lightgbm as lgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of resampled data:\n",
      " train shape...  (15219, 94) (15219,)\n",
      " test shape....  (6523, 94) (6523,)\n"
     ]
    }
   ],
   "source": [
    "DATASET_LOCAL_PATH = \"C:/Users/affiqazrin/Desktop/mmlspark/Data_FinalProject_READY4.csv\"\n",
    "df = pd.read_csv(DATASET_LOCAL_PATH)\n",
    "    \n",
    "ALL_COLS = [\"age\", #numerical\n",
    "            \"job\", #categorical\n",
    "            \"marital\", #categorical\n",
    "            \"education\", #categorical\n",
    "            \"default\", #categorical\n",
    "            \"housing\", #categorical, binary\n",
    "            \"loan\", #categorical, binary\n",
    "            \"contact\", #categorical\n",
    "            \"day\", #categorical\n",
    "            \"month\", #categorical\n",
    "            \"duration\", #numerical\n",
    "            \"campaign\", #categorical\n",
    "            \"pdays\", #numerical\n",
    "            \"previous\", #numerical\n",
    "            \"poutcome\", #categorical\n",
    "            \"deposit\", #categorical, binary\n",
    "           ]\n",
    "    \n",
    "NUMERICAL_COLS = [\"age\", #numerical\n",
    "                  \"duration\", #numerical\n",
    "                  \"pdays\", #numerical\n",
    "                  \"previous\", #numerical\n",
    "                 ]\n",
    "    \n",
    "CATEGORICAL_COLS = [\"job\", #categorical\n",
    "                    \"marital\", #categorical\n",
    "                    \"education\", #categorical\n",
    "                    \"default\", #categorical\n",
    "                    \"housing\", #categorical, binary\n",
    "                    \"loan\", #categorical, binary\n",
    "                    \"contact\", #categorical\n",
    "                    \"day\", #categorical\n",
    "                    \"month\", #categorical\n",
    "                    \"campaign\", #categorical\n",
    "                    \"poutcome\" #categorical\n",
    "                   ]\n",
    "\n",
    "TARGET_COL = [\"deposit\" #categorical, binary\n",
    "             ]\n",
    "    \n",
    "le = LabelEncoder()\n",
    "#TARGET_COL2 = le.fit_transform(df[TARGET_COL])\n",
    "TARGET_COL2 = df[TARGET_COL].apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "CATEGORICAL_COLS2 = pd.DataFrame(ohe.fit_transform(df[CATEGORICAL_COLS]).toarray())\n",
    "    \n",
    "DATA_PROCESSED = pd.concat([df[NUMERICAL_COLS], CATEGORICAL_COLS2], axis=1)\n",
    "mask = DATA_PROCESSED + TARGET_COL2\n",
    "    \n",
    "# Correlation_plot(model[mask], response_column)    \n",
    "X = DATA_PROCESSED.values\n",
    "y = TARGET_COL2.values.ravel()\n",
    "    \n",
    "sm = SMOTE(random_state=12)\n",
    "X_resampled, y_resampled = sm.fit_sample(X, y)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled,\n",
    "                                                        y_resampled,\n",
    "                                                        test_size = 0.3,\n",
    "                                                        random_state = 0)\n",
    "    \n",
    "print('Size of resampled data:')\n",
    "print(' train shape... ', X_train.shape, y_train.shape)\n",
    "print(' test shape.... ', X_test.shape, y_test.shape)\n",
    "    \n",
    "DATA_PROCESSED_HEADER=list(DATA_PROCESSED.columns.values)\n",
    "n_features = len(DATA_PROCESSED_HEADER)\n",
    "n_ALL_COLS = len(ALL_COLS)\n",
    "n_NUMERICAL_COLS = len(NUMERICAL_COLS)\n",
    "n_CATEGORICAL_COLS = len(CATEGORICAL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dataset into proper LGB format \n",
    "d_train=lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the parameters\n",
    "params={}\n",
    "params['learning_rate']=0.03\n",
    "params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
    "params['objective']='binary' #Binary target feature\n",
    "params['metric']='binary_logloss' #metric for binary classification\n",
    "params['max_depth']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 7567, number of negative: 7652\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14317\n",
      "[LightGBM] [Info] Number of data points in the train set: 15219, number of used features: 70\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497207 -> initscore=-0.011170\n",
      "[LightGBM] [Info] Start training from score -0.011170\n"
     ]
    }
   ],
   "source": [
    "#train the model \n",
    "clf=lgb.train(params,d_train,100) #train the model on 100 epocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on the test set\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rounding the values\n",
    "y_pred=y_pred.round(0)\n",
    "\n",
    "#converting from float to integer\n",
    "y_pred=y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC:  0.9478667588295318\n",
      "RMSE:  0.22897568333714344\n",
      "Precision Score:  0.9322033898305084\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC-AUC: \", roc_auc_score(y_pred,y_test))\n",
    "print(\"RMSE: \", sqrt(mean_squared_error(y_pred,y_test)))\n",
    "print(\"Precision Score: \", precision_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@nitin9809/lightgbm-binary-classification-multi-class-classification-regression-using-python-4f22032b36a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
